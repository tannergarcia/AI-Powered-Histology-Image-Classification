{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c601c47-d142-413f-a3e8-2949688bca86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /blue/vabfmc/data/working/d.uriartediaz/francokrepel/project-root\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "os.chdir(project_root)  # Change directory to project_root\n",
    "# Verify current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "# Now try importing\n",
    "from src.data_processing.patch_dataset import PatchDataset\n",
    "from src.data_processing.simclr_transforms import SimCLRTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217174ad-8bf0-4bad-9952-dffe8fb0d9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pytorch/2.2.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset and dataloader\n",
    "transform = SimCLRTransform(size=224)\n",
    "dataset = PatchDataset(root_dir='data/patches/BCC', transform=transform)\n",
    "batch_size = 256  # Adjust based on your GPU memory\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1119f3-b7ca-4d55-b67e-d6c7357d234a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Implement the training loop for SimCLR.\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from src.models.simclr_model import SimCLRModel\n",
    "from src.models.nt_xent_loss import NTXentLoss\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the SimCLR model\n",
    "model = SimCLRModel(base_model='resnet18', out_dim=128)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = NTXentLoss(batch_size=batch_size, temperature=0.5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100  # Adjust based on your needs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (xi, xj) in dataloader:\n",
    "        xi = xi.to(device)\n",
    "        xj = xj.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, zi = model(xi)\n",
    "        _, zj = model(xj)\n",
    "\n",
    "        loss = criterion(zi, zj)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    \n",
    "# saving the encoder part of the model for feature extraction.\n",
    "torch.save(model.encoder.state_dict(), 'models/simclr_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b809de-c3e2-4606-b5ed-ea4c1e0fc09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c8b12-9a72-4b50-b484-12d651676c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.2.0",
   "language": "python",
   "name": "pytorch-2.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
