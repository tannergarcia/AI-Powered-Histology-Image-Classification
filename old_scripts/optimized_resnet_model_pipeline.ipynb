{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752a101d-919c-459f-a43c-743d3478a3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.7.0\n",
      "Available GPU Memory (MB): [59348, 81037, 81037, 81037, 81037, 60592, 81034, 81037]\n",
      "Batch Size per GPU: [58, 80, 80, 80, 80, 60, 80, 80]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, ZeroPadding2D, Conv2D, BatchNormalization,\n",
    "                                     Activation, MaxPooling2D, Add, Flatten, Dense, Dropout)\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "# Ensure TensorFlow version is compatible (2.x)\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# ========================\n",
    "# Dynamic Batch Size Adjustment\n",
    "# ========================\n",
    "\n",
    "def get_available_gpu_memory():\n",
    "    try:\n",
    "        # Execute nvidia-smi command to get memory details\n",
    "        result = subprocess.check_output(\n",
    "            ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        # Parse the result\n",
    "        memory_free = [int(x) for x in result.strip().split('\\n')]\n",
    "        return memory_free\n",
    "    except Exception as e:\n",
    "        print(\"Error querying GPU memory:\", e)\n",
    "        # Default to a safe batch size if querying fails\n",
    "        return [0]\n",
    "\n",
    "def determine_batch_size(memory_free, memory_per_image=1000):\n",
    "    \"\"\"\n",
    "    Determine batch size based on available GPU memory.\n",
    "    Args:\n",
    "        memory_free (list): List of free memory (MB) per GPU.\n",
    "        memory_per_image (int): Estimated memory usage per image (MB).\n",
    "    Returns:\n",
    "        batch_size (int): Suitable batch size per GPU.\n",
    "    \"\"\"\n",
    "    # Define a buffer to prevent memory over-allocation\n",
    "    buffer = 500  # MB\n",
    "    batch_size = []\n",
    "    for mem in memory_free:\n",
    "        max_images = (mem - buffer) // memory_per_image\n",
    "        # Ensure at least a batch size of 1\n",
    "        batch_size.append(max(1, max_images))\n",
    "    return batch_size\n",
    "\n",
    "# Get available GPU memory\n",
    "memory_free = get_available_gpu_memory()\n",
    "print(\"Available GPU Memory (MB):\", memory_free)\n",
    "\n",
    "# Determine batch size per GPU\n",
    "batch_size_per_gpu = determine_batch_size(memory_free)\n",
    "print(\"Batch Size per GPU:\", batch_size_per_gpu)\n",
    "\n",
    "# Total batch size is sum of batch sizes per GPU\n",
    "total_batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4c66fb-036c-4796-89d0-652141e2c98f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete DataFrame:\n",
      "                                          image_path  binary_label study_id\n",
      "0  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M378\n",
      "1  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M378\n",
      "2  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M378\n",
      "3  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M378\n",
      "4  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M378\n",
      "\n",
      "Training Data:\n",
      "                                           image_path  binary_label study_id\n",
      "6   /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M378\n",
      "40  /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M386\n",
      "76  /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M393\n",
      "43  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M387\n",
      "32  /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M384\n",
      "\n",
      "Testing Data:\n",
      "                                            image_path  binary_label study_id\n",
      "204  /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M425\n",
      "38   /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M386\n",
      "8    /home/d.uriartediaz/vabfmc/data/working/d.uria...             1     M379\n",
      "202  /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M423\n",
      "65   /home/d.uriartediaz/vabfmc/data/working/d.uria...             0     M390\n",
      "\n",
      "Overall distribution (total count):\n",
      "0    106\n",
      "1    102\n",
      "Name: binary_label, dtype: int64\n",
      "\n",
      "Training distribution (total count):\n",
      "No Cancer (0): 85\n",
      "Cancer (1): 81\n",
      "\n",
      "Testing distribution (total count):\n",
      "No Cancer (0): 21\n",
      "Cancer (1): 21\n",
      "\n",
      "Total number of images:\n",
      "Overall: 208\n",
      "Training: 166\n",
      "Testing: 42\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Data Preparation\n",
    "# ========================\n",
    "\n",
    "# Paths to your CSV and image directories\n",
    "bcc_labels_path = '/home/d.uriartediaz/vabfmc/data/working/d.uriartediaz/francokrepel/project-root/data/BCC_labels.csv'\n",
    "slides_dir = '/home/d.uriartediaz/vabfmc/data/working/d.uriartediaz/1792x1792'\n",
    "\n",
    "# Load labels\n",
    "bcc_labels_df = pd.read_csv(bcc_labels_path)\n",
    "\n",
    "# Process labels\n",
    "bcc_labels_df = bcc_labels_df[['slide_id', 'StudyID #', 'label']]\n",
    "bcc_labels_df['binary_label'] = bcc_labels_df['label'].apply(lambda x: 1 if x == \"Present\" else 0)\n",
    "\n",
    "# Initialize lists to store matched file paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "study_ids = []\n",
    "\n",
    "# Match image paths with labels\n",
    "for _, row in bcc_labels_df.iterrows():\n",
    "    slide_id = row['slide_id']\n",
    "    study_id = row['StudyID #']\n",
    "    label = row['binary_label']\n",
    "    \n",
    "    folder_path = os.path.join(slides_dir, slide_id)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(folder_path, file_name))\n",
    "                labels.append(label)\n",
    "                study_ids.append(study_id)\n",
    "    else:\n",
    "        print(f\"Warning: Directory not found for slide_id: {slide_id}\")\n",
    "\n",
    "# Create DataFrame\n",
    "data_df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'binary_label': labels,\n",
    "    'study_id': study_ids\n",
    "})\n",
    "\n",
    "# Ensure DataFrame is not empty\n",
    "if data_df.empty:\n",
    "    raise ValueError(\"No matching images were found. Please verify the directory paths and slide IDs.\")\n",
    "else:\n",
    "    # Display the first few rows of data_df\n",
    "    print(\"Complete DataFrame:\")\n",
    "    print(data_df.head())\n",
    "\n",
    "    # Split data\n",
    "    train_df, test_df = train_test_split(data_df, test_size=0.2, stratify=data_df['binary_label'], random_state=42)\n",
    "\n",
    "    # Display the first few rows of the training and test data\n",
    "    print(\"\\nTraining Data:\")\n",
    "    print(train_df.head())\n",
    "    print(\"\\nTesting Data:\")\n",
    "    print(test_df.head())\n",
    "\n",
    "    # Get the number of images for each label in the overall, training, and testing datasets\n",
    "    print(\"\\nOverall distribution (total count):\")\n",
    "    print(data_df['binary_label'].value_counts())\n",
    "    \n",
    "    print(\"\\nTraining distribution (total count):\")\n",
    "    print(\"No Cancer (0):\", train_df['binary_label'].value_counts().get(0, 0))\n",
    "    print(\"Cancer (1):\", train_df['binary_label'].value_counts().get(1, 0))\n",
    "    \n",
    "    print(\"\\nTesting distribution (total count):\")\n",
    "    print(\"No Cancer (0):\", test_df['binary_label'].value_counts().get(0, 0))\n",
    "    print(\"Cancer (1):\", test_df['binary_label'].value_counts().get(1, 0))\n",
    "    \n",
    "    # Get the total number of images in each set\n",
    "    print(\"\\nTotal number of images:\")\n",
    "    print(\"Overall:\", len(data_df))\n",
    "    print(\"Training:\", len(train_df))\n",
    "    print(\"Testing:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7a01ae-4080-40bb-95e5-71deec7d6832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 166 validated image filenames belonging to 2 classes.\n",
      "Found 42 validated image filenames belonging to 2 classes.\n",
      "Train Generator - First Batch\n",
      "Batch shape (images): (16, 1792, 1792, 3)\n",
      "Batch shape (labels): (16,)\n",
      "Sample labels from train batch: [1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "\n",
      "Test Generator - First Batch\n",
      "Batch shape (images): (16, 1792, 1792, 3)\n",
      "Batch shape (labels): (16,)\n",
      "Sample labels from test batch: [1. 1. 0. 1. 0. 0. 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Make explicit copies to avoid SettingWithCopyWarning\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "\n",
    "# Convert binary labels to strings\n",
    "train_df['binary_label'] = train_df['binary_label'].astype(str)\n",
    "test_df['binary_label'] = test_df['binary_label'].astype(str)\n",
    "\n",
    "# Function to create generators\n",
    "def create_generator(datagen, df, batch_size):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='image_path',\n",
    "        y_col='binary_label',\n",
    "        target_size=(1792, 1792),\n",
    "        color_mode='rgb',\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "# Define ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create Generators\n",
    "train_generator = create_generator(train_datagen, train_df, batch_size=total_batch_size)\n",
    "test_generator = create_generator(test_datagen, test_df, batch_size=total_batch_size)\n",
    "\n",
    "\n",
    "# Check the first batch from the train generator\n",
    "train_batch = next(train_generator)\n",
    "test_batch = next(test_generator)\n",
    "\n",
    "# Print details of the train batch\n",
    "print(\"Train Generator - First Batch\")\n",
    "print(\"Batch shape (images):\", train_batch[0].shape)\n",
    "print(\"Batch shape (labels):\", train_batch[1].shape)\n",
    "print(\"Sample labels from train batch:\", train_batch[1][:10])  # Display first 10 labels\n",
    "\n",
    "# Print details of the test batch\n",
    "print(\"\\nTest Generator - First Batch\")\n",
    "print(\"Batch shape (images):\", test_batch[0].shape)\n",
    "print(\"Batch shape (labels):\", test_batch[1].shape)\n",
    "print(\"Sample labels from test batch:\", test_batch[1][:10])  # Display first 10 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c251f9a9-333a-4b0d-8d53-017a5dccf94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-80GB, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Model Definition\n",
    "# ========================\n",
    "\n",
    "# Set mixed precision policy\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# Define res_identity and res_conv functions\n",
    "def res_identity(x, filters):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # First block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add input (skip connection)\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters):\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # First block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Shortcut path\n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid',\n",
    "                    kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # Add input (skip connection)\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet_1792_head(input_shape):\n",
    "    input_im = Input(shape=input_shape)\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "\n",
    "    x = Conv2D(8, kernel_size=(7, 7), strides=(2, 2), kernel_regularizer=l2(0.001))(x)  # Output size 896\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)  # Output size 448\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(8, 32))\n",
    "    x = res_identity(x, filters=(8, 32))\n",
    "    x = res_identity(x, filters=(8, 32))\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(16, 64))  # Output Size 224\n",
    "    x = res_identity(x, filters=(16, 64))\n",
    "    x = res_identity(x, filters=(16, 64))\n",
    "    x = res_identity(x, filters=(16, 64))\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(32, 128))  # Output size 112\n",
    "    x = res_identity(x, filters=(32, 128))\n",
    "    x = res_identity(x, filters=(32, 128))\n",
    "    x = res_identity(x, filters=(32, 128))\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(1, 1), strides=(2, 2), padding='valid',\n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='HiResnet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "def HiResNet(size, weights, classes):\n",
    "    if size == 1792:\n",
    "        input_shape = (1792, 1792, 3)\n",
    "        hi_res_head = resnet_1792_head(input_shape)\n",
    "    else:\n",
    "        raise ValueError('Invalid size for Hi-ResNet head.')\n",
    "\n",
    "    if weights == \"Res50\":\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    elif weights == \"None\":\n",
    "        base_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "    else:\n",
    "        raise ValueError('weights should be either: \"Res50\" or \"None\"')\n",
    "\n",
    "    truncated_model = Model(inputs=base_model.layers[7].input, outputs=base_model.layers[-1].output)\n",
    "    final_model = truncated_model(hi_res_head.output)\n",
    "    model = Model(inputs=hi_res_head.input, outputs=final_model, name='HiResnet')\n",
    "\n",
    "    # Add custom top layers\n",
    "    head_model = MaxPooling2D(pool_size=(4, 4))(model.output)\n",
    "    head_model = Flatten(name='flatten')(head_model)\n",
    "    head_model = Dense(1024, activation='relu')(head_model)\n",
    "    head_model = Dropout(0.1)(head_model)\n",
    "    head_model = Dense(512, activation='relu')(head_model)\n",
    "    head_model = Dropout(0.1)(head_model)\n",
    "    head_model = Dense(classes, activation='sigmoid', dtype='float32')(head_model)  # Ensure output is float32\n",
    "\n",
    "    return Model(model.input, head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b009ac5b-90c2-4727-bd62-506cdea8e855",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:54:18.230821: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 14:54:19.036587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78902 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1792, 1792,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 1798, 1798,   0          ['input_1[0][0]']                \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 896, 896, 8)  1184        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 896, 896, 8)  32         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 896, 896, 8)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 898, 898, 8)  0          ['activation[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 448, 448, 8)  0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 448, 448, 8)  72          ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 448, 448, 8)  584         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 448, 448, 32  288         ['activation_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 448, 448, 32  288         ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 448, 448, 32  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 448, 448, 32  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 448, 448, 32  0           ['batch_normalization_3[0][0]',  \n",
      "                                )                                 'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 448, 448, 32  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 448, 448, 8)  264         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 448, 448, 8)  584         ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 448, 448, 32  288         ['activation_5[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 448, 448, 32  128        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 448, 448, 32  0           ['batch_normalization_7[0][0]',  \n",
      "                                )                                 'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 448, 448, 32  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 448, 448, 8)  264         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 448, 448, 8)  584         ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 448, 448, 8)  32         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 448, 448, 8)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 448, 448, 32  288         ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 448, 448, 32  128        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 448, 448, 32  0           ['batch_normalization_10[0][0]', \n",
      "                                )                                 'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 448, 448, 32  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 16  528         ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 16  64         ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 224, 224, 16  2320        ['activation_10[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 224, 224, 16  64         ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 224, 224, 64  1088        ['activation_11[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 224, 224, 64  2112        ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 224, 224, 64  256        ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 224, 224, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_13[0][0]', \n",
      "                                )                                 'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 224, 224, 64  0           ['add_3[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 224, 224, 16  1040        ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 224, 224, 16  64         ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 224, 224, 16  2320        ['activation_13[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 224, 224, 16  64         ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 224, 224, 64  1088        ['activation_14[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 224, 224, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_17[0][0]', \n",
      "                                )                                 'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 224, 224, 64  0           ['add_4[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 224, 224, 16  1040        ['activation_15[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 224, 224, 16  64         ['conv2d_18[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_18[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 224, 224, 16  2320        ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 224, 224, 16  64         ['conv2d_19[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_19[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 224, 224, 64  1088        ['activation_17[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 224, 224, 64  256        ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_20[0][0]', \n",
      "                                )                                 'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 224, 224, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 224, 224, 16  1040        ['activation_18[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 224, 224, 16  64         ['conv2d_21[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_21[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 224, 224, 16  2320        ['activation_19[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 224, 224, 16  64         ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 224, 224, 64  1088        ['activation_20[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 224, 224, 64  256        ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_23[0][0]', \n",
      "                                )                                 'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 224, 224, 64  0           ['add_6[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 112, 112, 32  2080        ['activation_21[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 112, 112, 32  128        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 112, 112, 32  9248        ['activation_22[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 112, 112, 32  128        ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_25[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 112, 112, 12  4224        ['activation_23[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 112, 112, 12  8320        ['activation_21[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 112, 112, 12  512        ['conv2d_26[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 112, 112, 12  512        ['conv2d_27[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 112, 112, 12  0           ['batch_normalization_26[0][0]', \n",
      "                                8)                                'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 112, 112, 12  0           ['add_7[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 112, 112, 32  4128        ['activation_24[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 112, 112, 32  128        ['conv2d_28[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 112, 112, 32  9248        ['activation_25[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 112, 112, 32  128        ['conv2d_29[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_29[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 112, 112, 12  4224        ['activation_26[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 112, 112, 12  512        ['conv2d_30[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 112, 112, 12  0           ['batch_normalization_30[0][0]', \n",
      "                                8)                                'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 112, 112, 12  0           ['add_8[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 112, 112, 32  4128        ['activation_27[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 112, 112, 32  128        ['conv2d_31[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_31[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 112, 112, 32  9248        ['activation_28[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 112, 112, 32  128        ['conv2d_32[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_32[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 112, 112, 12  4224        ['activation_29[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 112, 112, 12  512        ['conv2d_33[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 112, 112, 12  0           ['batch_normalization_33[0][0]', \n",
      "                                8)                                'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 112, 112, 12  0           ['add_9[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 112, 112, 32  4128        ['activation_30[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 112, 112, 32  128        ['conv2d_34[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 112, 112, 32  9248        ['activation_31[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 112, 112, 32  128        ['conv2d_35[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 112, 112, 12  4224        ['activation_32[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 112, 112, 12  512        ['conv2d_36[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 112, 112, 12  0           ['batch_normalization_36[0][0]', \n",
      "                                8)                                'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 112, 112, 12  0           ['add_10[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 56, 56, 64)   8256        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 56, 56, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 7, 7, 2048)   23577984    ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 2048)  0           ['model[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         2098176     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          524800      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            513         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,316,849\n",
      "Trainable params: 26,260,673\n",
      "Non-trainable params: 56,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:54:31.972900: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_13743\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:55:04.281059: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-11-12 14:55:06.367038: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - ETA: 0s - loss: 2.3440 - accuracy: 0.3976 - auc: 0.4211 - precision: 0.4188 - recall: 0.6049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:56:28.893046: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_56460\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:21\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.54997, saving model to HiResNet_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 126s 9s/step - loss: 2.3440 - accuracy: 0.3976 - auc: 0.4211 - precision: 0.4188 - recall: 0.6049 - val_loss: 2.5500 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.1190 - accuracy: 0.5301 - auc: 0.5139 - precision: 0.5165 - recall: 0.5802\n",
      "Epoch 00002: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 94s 9s/step - loss: 2.1190 - accuracy: 0.5301 - auc: 0.5139 - precision: 0.5165 - recall: 0.5802 - val_loss: 4.0892 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.9755 - accuracy: 0.5783 - auc: 0.5975 - precision: 0.5679 - recall: 0.5679\n",
      "Epoch 00003: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 94s 9s/step - loss: 1.9755 - accuracy: 0.5783 - auc: 0.5975 - precision: 0.5679 - recall: 0.5679 - val_loss: 4.2378 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.7017 - accuracy: 0.6325 - auc: 0.6966 - precision: 0.6389 - recall: 0.5679\n",
      "Epoch 00004: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 95s 9s/step - loss: 1.7017 - accuracy: 0.6325 - auc: 0.6966 - precision: 0.6389 - recall: 0.5679 - val_loss: 5.2920 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.5727 - accuracy: 0.7169 - auc: 0.7752 - precision: 0.7024 - recall: 0.7284\n",
      "Epoch 00005: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 94s 9s/step - loss: 1.5727 - accuracy: 0.7169 - auc: 0.7752 - precision: 0.7024 - recall: 0.7284 - val_loss: 5.8375 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.5488 - accuracy: 0.7470 - auc: 0.7911 - precision: 0.7468 - recall: 0.7284\n",
      "Epoch 00006: val_loss did not improve from 2.54997\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "11/11 [==============================] - 95s 9s/step - loss: 1.5488 - accuracy: 0.7470 - auc: 0.7911 - precision: 0.7468 - recall: 0.7284 - val_loss: 8.0888 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4114 - accuracy: 0.7470 - auc: 0.8367 - precision: 0.7407 - recall: 0.7407\n",
      "Epoch 00007: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 95s 9s/step - loss: 1.4114 - accuracy: 0.7470 - auc: 0.8367 - precision: 0.7407 - recall: 0.7407 - val_loss: 9.5925 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-06\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.5447 - accuracy: 0.6988 - auc: 0.7777 - precision: 0.6782 - recall: 0.7284\n",
      "Epoch 00008: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 95s 9s/step - loss: 1.5447 - accuracy: 0.6988 - auc: 0.7777 - precision: 0.6782 - recall: 0.7284 - val_loss: 11.5882 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-06\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6159 - accuracy: 0.6988 - auc: 0.7849 - precision: 0.6667 - recall: 0.7654\n",
      "Epoch 00009: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 94s 8s/step - loss: 1.6159 - accuracy: 0.6988 - auc: 0.7849 - precision: 0.6667 - recall: 0.7654 - val_loss: 14.9755 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-06\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4325 - accuracy: 0.7470 - auc: 0.8348 - precision: 0.7746 - recall: 0.6790\n",
      "Epoch 00010: val_loss did not improve from 2.54997\n",
      "11/11 [==============================] - 94s 8s/step - loss: 1.4325 - accuracy: 0.7470 - auc: 0.8348 - precision: 0.7746 - recall: 0.6790 - val_loss: 20.1322 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-06\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4952 - accuracy: 0.7229 - auc: 0.7911 - precision: 0.7215 - recall: 0.7037\n",
      "Epoch 00011: val_loss did not improve from 2.54997\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "11/11 [==============================] - 94s 8s/step - loss: 1.4952 - accuracy: 0.7229 - auc: 0.7911 - precision: 0.7215 - recall: 0.7037 - val_loss: 21.6206 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-06\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Model Compilation and Training\n",
    "# ========================\n",
    "\n",
    "# Define the distribution strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices:', strategy.num_replicas_in_sync)\n",
    "\n",
    "# Build and compile the model within the strategy scope\n",
    "with strategy.scope():\n",
    "    model = HiResNet(size=1792, weights=\"Res50\", classes=1)\n",
    "\n",
    "    # Choose an optimizer\n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')]\n",
    "    )\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"HiResNet_best.h5\",\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_steps = math.ceil(train_generator.n / train_generator.batch_size)\n",
    "test_steps = math.ceil(test_generator.n / test_generator.batch_size)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_steps,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc981bad-77b5-4b68-b621-449f9967a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:42:41.282521: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_74873\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\022FlatMapDataset:231\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 1.8165 - accuracy: 0.5000 - auc: 0.4286 - precision: 0.5000 - recall: 1.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiResNet_best.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_generator, steps\u001b[38;5;241m=\u001b[39mtest_steps)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Model Evaluation\n",
    "# ========================\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights(\"HiResNet_best.h5\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Generate predictions\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict(test_generator, steps=test_steps)\n",
    "y_pred = (Y_pred > 0.5).astype(int).flatten()\n",
    "y_true = test_generator.classes[:len(y_pred)]\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Cancerous', 'Cancerous']))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Non-Cancerous', 'Cancerous'],\n",
    "            yticklabels=['Non-Cancerous', 'Cancerous'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot AUC\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history.history['auc'], label='Train AUC')\n",
    "    plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "    plt.title('AUC over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Precision\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history.history['precision'], label='Train Precision')\n",
    "    plt.plot(history.history['val_precision'], label='Validation Precision')\n",
    "    plt.title('Precision over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Recall\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(history.history['recall'], label='Train Recall')\n",
    "    plt.plot(history.history['val_recall'], label='Validation Recall')\n",
    "    plt.title('Recall over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f368490-1572-4a96-8357-63a6910fa1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
