{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847f8bb9-82c6-49b1-b46e-9c5761fc31e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Enable mixed precision\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d497617b-9d50-4e97-ae5d-375fdb283236",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tissue images per slide: {'slide-2022-02-09T12-26-27-R5-S1': 3, 'slide-2022-02-09T12-28-49-R5-S2': 3, 'slide-2022-02-09T12-30-52-R5-S3': 2, 'slide-2022-02-09T12-33-12-R5-S4': 2, 'slide-2022-02-09T12-36-31-R5-S5': 1, 'slide-2022-02-09T12-38-53-R5-S6': 2, 'slide-2022-02-09T12-41-58-R5-S7': 1, 'slide-2022-02-09T12-44-19-R5-S8': 2, 'slide-2022-02-09T12-47-21-R5-S9': 4, 'slide-2022-02-09T13-08-40-R5-S17': 2, 'slide-2022-02-09T13-11-39-R5-S18': 2, 'slide-2022-02-09T13-14-10-R5-S19': 2, 'slide-2022-02-09T13-15-57-R5-S20': 3, 'slide-2022-02-09T13-18-39-R5-S21': 4, 'slide-2022-02-09T13-21-07-R5-S22': 3, 'slide-2022-02-09T13-23-51-R5-S23': 2, 'slide-2022-02-09T13-26-16-R5-S24': 2, 'slide-2022-02-09T13-29-07-R5-S25': 2, 'slide-2022-02-09T13-31-46-R6-S1': 2, 'slide-2022-02-09T13-33-41-R6-S2': 4, 'slide-2022-02-09T13-36-50-R6-S3': 2, 'slide-2022-02-09T13-39-43-R6-S4': 3, 'slide-2022-02-09T13-42-12-R6-S5': 3, 'slide-2022-02-09T13-44-36-R6-S6': 2, 'slide-2022-02-09T13-46-51-R6-S7': 5, 'slide-2022-02-09T13-48-54-R6-S8': 3, 'slide-2022-02-09T13-50-59-R6-S9': 2, 'slide-2022-02-09T13-52-44-R6-S10': 2, 'slide-2022-02-09T13-55-01-R6-S11': 2, 'slide-2022-02-09T13-57-33-R6-S12': 2, 'slide-2022-02-09T13-59-49-R6-S13': 1, 'slide-2022-02-09T14-01-56-R6-S14': 1, 'slide-2022-02-09T14-03-23-R6-S15': 2, 'slide-2022-02-09T14-06-34-R6-S16': 3, 'slide-2022-02-09T14-08-57-R6-S17': 3, 'slide-2022-02-09T14-11-51-R6-S18': 1, 'slide-2022-02-09T14-14-45-R6-S19': 2, 'slide-2022-02-09T14-16-36-R6-S20': 2, 'slide-2022-02-09T14-18-51-R6-S21': 3, 'slide-2022-02-09T14-20-39-R6-S22': 2, 'slide-2022-02-09T14-22-21-R6-S23': 3, 'slide-2022-02-09T14-23-53-R6-S24': 2, 'slide-2022-02-09T14-26-43-R6-S25': 2, 'slide-2022-02-09T14-41-26-R7-S5': 3, 'slide-2022-02-09T14-43-16-R7-S6': 3, 'slide-2022-02-09T14-45-25-R7-S7': 3, 'slide-2022-02-09T14-47-32-R7-S8': 3, 'slide-2022-02-09T14-49-24-R7-S9': 2, 'slide-2022-02-09T14-51-51-R7-S10': 3, 'slide-2022-02-09T14-53-47-R7-S11': 2, 'slide-2022-02-09T14-56-25-R7-S12': 2, 'slide-2022-02-09T14-58-16-R7-S13': 1, 'slide-2022-02-09T15-00-33-R7-S14': 2, 'slide-2022-02-09T15-02-11-R7-S15': 4, 'slide-2022-02-09T15-05-03-R7-S16': 3, 'slide-2022-02-09T15-06-50-R7-S17': 2, 'slide-2022-02-09T15-08-42-R7-S18': 4, 'slide-2022-02-09T15-10-26-R7-S19': 1, 'slide-2022-02-09T15-12-27-R7-S20': 4, 'slide-2022-02-09T15-15-02-R7-S21': 3, 'slide-2022-02-09T15-16-56-R7-S22': 3, 'slide-2022-02-09T15-18-21-R7-S23': 2, 'slide-2022-02-09T15-20-24-R7-S24': 3, 'slide-2022-02-09T15-22-45-R7-S25': 1, 'slide-2022-02-09T15-26-14-R8-S1': 4, 'slide-2022-02-09T15-28-54-R8-S2': 1, 'slide-2022-02-09T15-31-49-R8-S3': 1, 'slide-2022-02-09T15-34-24-R8-S4': 1, 'slide-2022-02-09T15-37-14-R8-S5': 1, 'slide-2022-02-09T15-39-07-R8-S6': 3, 'slide-2022-02-09T15-41-17-R8-S7': 3, 'slide-2022-02-09T15-43-43-R8-S8': 2, 'slide-2022-02-09T15-46-56-R8-S9': 2, 'slide-2022-02-09T15-49-30-R8-S10': 1, 'slide-2022-02-09T15-52-31-R8-S11': 1, 'slide-2022-02-09T15-55-26-R8-S12': 3, 'slide-2022-02-09T15-58-32-R8-S13': 2, 'slide-2022-02-09T16-01-16-R8-S14': 2, 'slide-2022-02-09T16-04-32-R8-S15': 1, 'slide-2022-02-09T16-07-00-R8-S16': 2, 'slide-2022-02-09T16-09-56-R8-S17': 2, 'slide-2022-02-09T16-23-42-R8-S22': 2, 'slide-2022-02-09T16-27-06-R8-S23': 2, 'slide-2022-02-09T16-29-48-R8-S24': 1, 'slide-2022-02-09T16-33-19-R8-S25': 1, 'slide-2022-02-09T16-37-24-R9-S1': 1, 'slide-2022-02-09T16-40-50-R9-S2': 3, 'slide-2022-02-09T16-44-03-R9-S3': 2, 'slide-2022-02-09T16-46-59-R9-S4': 2, 'slide-2022-02-09T16-50-23-R9-S5': 2, 'slide-2022-02-09T17-09-29-R9-S11': 2, 'slide-2022-02-09T17-12-02-R9-S12': 3}\n",
      "Total tissue images found: 208\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir = '../1792x1792'  # Use the 1792x1792 images\n",
    "metadata_file = 'project-root/data/BCC_labels.csv'\n",
    "output_dir = 'organized_data'\n",
    "\n",
    "# Step 1: Load and process metadata\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "metadata['label'] = metadata['label'].map({'Clear': 0, 'Present': 1})  # Map labels to 0 and 1\n",
    "\n",
    "# Group by StudyID to split data\n",
    "grouped = metadata.groupby('StudyID #')\n",
    "\n",
    "# Count images per slide\n",
    "slide_counts = {}\n",
    "for slide_id in metadata['slide_id'].unique():\n",
    "    slide_folder = os.path.join(image_dir, slide_id)\n",
    "    if os.path.exists(slide_folder):\n",
    "        slide_counts[slide_id] = len([f for f in os.listdir(slide_folder) if f.endswith('.png')])\n",
    "    else:\n",
    "        slide_counts[slide_id] = 0\n",
    "\n",
    "print(f\"Tissue images per slide: {slide_counts}\")\n",
    "print(f\"Total tissue images found: {sum(slide_counts.values())}\")\n",
    "\n",
    "# Convert the keys to a list\n",
    "train_study_ids, val_study_ids = train_test_split(list(grouped.groups.keys()), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create organized directories for training and validation sets\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "val_dir = os.path.join(output_dir, 'val')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a57e7e-0691-4b65-bce2-93f7e36ebe7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images copied to organized_data/train: 165\n",
      "Total images copied to organized_data/val: 43\n"
     ]
    }
   ],
   "source": [
    "def organize_images(group_ids, dest_dir):\n",
    "    total_copied = 0  # Track copied images\n",
    "    for study_id in group_ids:\n",
    "        group = grouped.get_group(study_id)\n",
    "        for _, row in group.iterrows():\n",
    "            slide_id = row['slide_id']\n",
    "            label = row['label']\n",
    "            label_dir = 'Clear' if label == 0 else 'Present'\n",
    "            source_dir = os.path.join(image_dir, slide_id)\n",
    "            dest_label_dir = os.path.join(dest_dir, label_dir)\n",
    "            os.makedirs(dest_label_dir, exist_ok=True)\n",
    "            if os.path.exists(source_dir):\n",
    "                for file in os.listdir(source_dir):\n",
    "                    if file.endswith('.png'):\n",
    "                        # Append slide_id to filename to prevent overwriting\n",
    "                        new_file_name = f\"{slide_id}_{file}\"\n",
    "                        shutil.copy(\n",
    "                            os.path.join(source_dir, file),\n",
    "                            os.path.join(dest_label_dir, new_file_name)\n",
    "                        )\n",
    "                        total_copied += 1\n",
    "    print(f\"Total images copied to {dest_dir}: {total_copied}\")\n",
    "\n",
    "# Organize images\n",
    "organize_images(train_study_ids, train_dir)\n",
    "organize_images(val_study_ids, val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c66a18-de77-4752-9654-4355d93823a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165 images belonging to 2 classes.\n",
      "Found 43 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Use ImageDataGenerator for data loading\n",
    "image_size = (1792, 1792)\n",
    "batch_size = 4  # Adjusted batch size to fit GPU memory\n",
    "\n",
    "# Define ImageDataGenerators with appropriate preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
    ")\n",
    "\n",
    "# Create Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a25c83-0a05-451b-9b83-ecbeb49f60b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Load the Pre-trained ResNet-50 model without the top layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(1792, 1792, 3))\n",
    "\n",
    "# Freeze the base model layers initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Step 4: Build the model\n",
    "inputs = layers.Input(shape=(1792, 1792, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid', dtype='float32')(x)  # Set dtype to float32 for mixed precision\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Set up callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss'),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0c6a9-24cb-472c-9012-806bf216d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
